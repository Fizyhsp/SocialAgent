{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "with open('data/anthropopathic_data/complete_twitter_users.json') as f:\n",
    "    twitter = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T07:08:32.720217100Z",
     "start_time": "2023-08-14T07:08:32.391159500Z"
    }
   },
   "id": "c22feebf3220754c"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "167"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T07:08:39.969029Z",
     "start_time": "2023-08-14T07:08:39.890732400Z"
    }
   },
   "id": "6327820401cd71de"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14601\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for t in twitter:\n",
    "    c += len(t['likes'])\n",
    "    c += len(t['timeline'])\n",
    "    c += len(t['mentions'])\n",
    "    # for x in t['likes']:\n",
    "    #     x['type'] = 'likes'\n",
    "    # for x in t['timeline']:\n",
    "    #     x['type'] = 'timeline'\n",
    "    # for x in t['mentions']:\n",
    "    #     x['type'] = 'mentions'\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T07:10:02.729069100Z",
     "start_time": "2023-08-14T07:10:02.589964500Z"
    }
   },
   "id": "721efcd3c22dbb8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "980c6d15310a86c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "190faf2abc9424f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2b72e04cbcda8a91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t = twitter[28]\n",
    "ut =  t['mentions'] + t['likes'] + t['timeline']\n",
    "sut = sorted(ut, key=lambda x: x['created_at'])\n",
    "[s['created_at'] + ' ' + s['type'] for s in sut]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad896d93a86e5ea1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "texts = []\n",
    "created_ats = []\n",
    "ids = []\n",
    "authors = []\n",
    "from_users = []\n",
    "from_user_ids = []\n",
    "for t in twitter:\n",
    "    for x in t['likes']:\n",
    "        x['type'] = 'likes'\n",
    "    for x in t['timeline']:\n",
    "        x['type'] = 'timeline'\n",
    "    for x in t['mentions']:\n",
    "        x['type'] = 'mentions'\n",
    "    for l in t['likes'] + t['timeline'] + t['mentions']:\n",
    "        texts.append(l['text'])\n",
    "        created_ats.append(l['created_at'])\n",
    "        ids.append(l['id'])\n",
    "        authors.append(l['author_id'])\n",
    "        from_users.append(t['username'])\n",
    "        from_user_ids.append(t[\"id\"])\n",
    "env_posts = pd.DataFrame({\"id\": ids, \"author\": authors, \"text\": texts, \"created_at\": created_ats, \"from_user\": from_users, \"from_user_id\": from_user_ids})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57bc71ff390620d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env_posts.to_csv('toy_dir/twitter/env_posts.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "446fcb1acbc50d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_cols = ['profile_image_url', 'username', 'description', 'id', 'protected', 'created_at', 'name', 'verified', 'follower_count', 'member_count', 'owner_id']\n",
    "users = pd.DataFrame(columns=user_cols)\n",
    "for item in twitter:\n",
    "    data_to_add = {key: item[key] for key in user_cols}\n",
    "    users = users.append(data_to_add, ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ac61b4481d33994"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "users.to_csv('toy_dir/twitter/env_users.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73595851a6e6fa59"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reddit"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8847e33fa20632dc"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "with open('data/anthropopathic_data/reddit_user_popular_706.json', 'r', encoding='utf-8') as f:\n",
    "    reddit = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T07:11:02.700340200Z",
     "start_time": "2023-08-14T07:11:01.546067900Z"
    }
   },
   "id": "15c0ca1c5e830557"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "706"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T07:11:11.614061800Z",
     "start_time": "2023-08-14T07:11:11.536499700Z"
    }
   },
   "id": "a7e8673d47ccc3ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import utils"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3924f3fe5327c36e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rd['actions']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ea3fab95b9b831d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for rd in reddit:\n",
    "    character_path = os.path.join('toy_dir/reddit/characters', rd['username'])\n",
    "    utils.create_directory_if_not_exists(character_path)\n",
    "    profile = {\n",
    "        \"interested_topics\": rd['topics']\n",
    "    }\n",
    "    \n",
    "    ca = sorted(rd['actions'], key=lambda x: x['publish_time'])\n",
    "    save_actions = []\n",
    "    for a in ca:\n",
    "        name = a['type']\n",
    "        act_time = a['publish_time']\n",
    "        if name == \"comment\":\n",
    "            action_args = {\"content\": a['content'], \"root\":  (a['root_parent'] or \"\") + (a['parent'] or \"\")}\n",
    "        elif name == \"submission\":\n",
    "            action_args = {\"content\": a['content']}\n",
    "        else:\n",
    "            raise Exception()\n",
    "        save_actions.append({\"name\": name, \"act_time\": act_time, \"action_args\": action_args})\n",
    "    with open(os.path.join(character_path, 'actions.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(save_actions, f, ensure_ascii=False)\n",
    "    with open(os.path.join(character_path, 'profile.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(profile, f, ensure_ascii=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3988a2f3d59106e6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4eac29b8d67c8295"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(reddit)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "147e4538495836b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 知乎"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "655eb3c3afee83d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('data/anthropopathic_data/zhihu.json', 'r', encoding='utf-8') as f:\n",
    "    zhihu = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62ff69ee5f45e2"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43367\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for zh in zhihu:\n",
    "    c += len(zh['actions'])\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T07:07:29.811847500Z",
     "start_time": "2023-08-14T07:07:29.805865600Z"
    }
   },
   "id": "4b37211b5317f7a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zh = zhihu[0]\n",
    "character_path = os.path.join('toy_dir/zhihu/characters', zh['urlToken'])\n",
    "os.mkdir(character_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20bdac5093a0d0d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "zh['location']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d57ba9b845490ed6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import utils"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef9eb293dc546f28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "users = []\n",
    "for zh in zhihu:\n",
    "    user = zh.copy()\n",
    "    user[\"interested_topics\"] = [list(topic.keys())[0] for topic in zh['topics']]\n",
    "    del user[\"actions\"]\n",
    "    users.append(user)\n",
    "users = pd.DataFrame(users)\n",
    "users = users.drop_duplicates(subset=['name'])\n",
    "users.to_csv('toy_dir/zhihu/env_users.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86f3913c0db1dbc5"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m users[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maction\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[0;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mD:\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3805\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3806\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3808\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "source": [
    "users[0]['action']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T07:06:14.053792300Z",
     "start_time": "2023-08-14T07:06:13.974324400Z"
    }
   },
   "id": "c9130e51aa2b98f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "posts = []\n",
    "for zh in zhihu:\n",
    "    ca = zh['actions']\n",
    "    for a in ca:\n",
    "        post = dict()\n",
    "        post['author'] = \"\"\n",
    "        post['text'] = (a['action_title'] or \"\") + (a['action_content'] or \"\")\n",
    "        post['created_at'] = \"\"\n",
    "        post['from_user'] = zh['name']\n",
    "        post['from_user_id'] = zh['urlToken']\n",
    "        posts.append(post)\n",
    "        \n",
    "posts = pd.DataFrame(posts)\n",
    "posts[\"id\"] = posts.index\n",
    "posts = posts.drop_duplicates(subset=['text'])\n",
    "posts.to_csv('toy_dir/zhihu/env_posts.csv', index=False)    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce1a7de3f266bd46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "posts.index"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "151adbcae683ec81"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for zh in zhihu:\n",
    "    character_path = os.path.join('toy_dir/zhihu/characters', zh['name'])\n",
    "    utils.create_directory_if_not_exists(character_path)\n",
    "    profile = {\n",
    "        'name': zh['name'],\n",
    "        'description': (zh['headline'] or \"\") + ';' + (zh['description'] or \"\"),\n",
    "        'gender': 'man' if zh['gender'] == 1 else 'woman' if zh['gender'] == 0 else 'unknown',\n",
    "        'occupation': (zh['business'] or \"\") + '&' + (zh['employment'] or \"\"),\n",
    "        'education': (zh['education'] or \"\"),\n",
    "        'location': (zh['ip_location'] or \"\") + '&' + (zh['location'] or \"\"),\n",
    "        \"interested_topics\": [list(topic.keys())[0] for topic in zh['topics']]\n",
    "    }\n",
    "    \n",
    "    action_map = {\"赞同了回答\": \"like\", \"回答了问题\": \"comment\", \"发布了想法\": \"post\", \"提出了问题\": \"post\", \"发表了文章\": \"post\", \"关注了问题\": \"follow_topic\", \"关注了收藏夹\": \"follow_topic\", \"赞同了文章\": \"like\", \"收藏了回答\": \"follow_topic\", \"添加了问题\": \"post\", \"收藏了文章\": \"follow_topic\", \"认可了回答\": \"like\"}\n",
    "    ca = sorted(zh['actions'], key=lambda x: x['action_time'])\n",
    "    save_actions = []\n",
    "    for a in ca:\n",
    "        name = action_map[a['action_type']]\n",
    "        act_time = a['action_time']\n",
    "        a['action_title'] = '' if a['action_title'] is None else a['action_title']\n",
    "        a['action_content'] = '' if a['action_content'] is None else a['action_content']\n",
    "        a['action_content'] = a['action_content'][0]['content'] if isinstance(a['action_content'], list) else a['action_content']\n",
    "        if name == \"like\":\n",
    "            action_args = {\"root\": a['action_title'] + a['action_content']}\n",
    "        elif name == \"comment\":\n",
    "            action_args = {\"root\": a['action_title'] + a['action_content']}\n",
    "        elif name == \"post\":\n",
    "            action_args = {\"content\": a['action_title'] + a['action_content']}\n",
    "        elif name == \"follow_topic\":\n",
    "            action_args = {\"keyword\": a['action_title'] + a['action_content']}\n",
    "        else:\n",
    "            raise Exception(\"No use action name\")\n",
    "        save_actions.append({\"name\": name, \"act_time\": act_time, \"action_args\": action_args})\n",
    "    with open(os.path.join(character_path, 'actions.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(save_actions, f, ensure_ascii=False)\n",
    "    with open(os.path.join(character_path, 'profile.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(profile, f, ensure_ascii=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb044b98b7c293a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eca7ffde78b54ffc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_actions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d196c1dfc9ef6fe7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from actions import *"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46a7351358381ca6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for action in ca:\n",
    "    if action['action_type'] == '赞同了回答':\n",
    "        ao = LikeAction()\n",
    "        ao.action_args = {\"content\": action['action_title'] + '\\n' + action['action_content']}\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "549fa240c43ee863"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ao.action_time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe029223defff269"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def zhihu_action_build(actions: dict):\n",
    "    f"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf1f176c3968e655"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "14cbbe40f3f46439"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e65f3d4320de2bc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e5caef454f0d24a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
